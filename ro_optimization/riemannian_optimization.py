#!/usr/bin/env python
"""
Main Riemannian Optimization routine.
"""

import os
import time
import torch
import torch.multiprocessing as mp
import matplotlib.pyplot as plt
from argparse import ArgumentParser

# Enable TF32 for float32 matrix multiplies on Ampere+ GPUs
torch.set_float32_matmul_precision('high')

# Local project imports
from .config_loader import load_riemannian_config
from .utils import flatten_tensor, unflatten_tensor
from .diffusion_utils import DiffusionWrapper, get_classifier_fn, get_score_fn, get_denoiser_fn, compute_discrete_time_from_target_snr
from .objectives import get_opt_fn
from .visualization_utils import visualize_trajectory, save_gif_from_rendered_images

from templates_latent import ffhq128_autoenc_latent
from templates_cls import ffhq128_autoenc_non_linear_cls
from experiment import LitModel
from experiment_classifier import ClsModel
from dataset import CelebAttrDataset

from data_geometry.optim_function import get_optim_function
from data_geometry.riemannian_optimization.retraction import create_retraction_fn
from data_geometry.riemannian_optimization import get_riemannian_optimizer


def riemannian_optimization(riem_config_path):
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    # Load Riemannian config
    riem_config = load_riemannian_config(riem_config_path)

    # Load autoencoder model
    print("Loading autoencoder model (latent config) ...")
    autoenc_conf = ffhq128_autoenc_latent()
    autoenc_conf.T_eval = 1000
    autoenc_conf.latent_T_eval = 1000
    model = LitModel(autoenc_conf)
    ckpt_path = os.path.join("checkpoints", autoenc_conf.name, "last.ckpt")
    print(f"Loading autoencoder checkpoint from {ckpt_path}")
    state = torch.load(ckpt_path, map_location="cpu")
    model.load_state_dict(state["state_dict"], strict=False)
    model.ema_model.eval()
    model.ema_model.to(device)

    if not hasattr(model.ema_model, "latent_net"):
        raise ValueError("Autoencoder model does not contain latent_net.")

    # Load classifier model
    print("Loading classifier model ...")
    cls_conf = ffhq128_autoenc_non_linear_cls()
    cls_model = ClsModel(cls_conf)
    cls_ckpt = os.path.join("checkpoints", cls_conf.name, "last.ckpt")
    print(f"Loading classifier checkpoint from {cls_ckpt}")
    cls_state = torch.load(cls_ckpt, map_location="cpu")
    cls_model.load_state_dict(cls_state["state_dict"], strict=False)
    cls_model.to(device)
    cls_model.eval()

    # Load dataset and select L samples WITHOUT the target attribute
    print("Loading dataset using classifier config ...")
    dataset = cls_model.load_dataset()
    target_class = "Eyeglasses"
    cls_id = CelebAttrDataset.cls_to_id[target_class]
    L = riem_config.get("num_samples", 4)

    print(f"Selecting {L} samples without attribute '{target_class}'...")
    selected_indices = []
    for i in range(len(dataset)):
        sample = dataset[i]
        if "labels" in sample and sample["labels"][cls_id] == -1:
            selected_indices.append(i)
        if len(selected_indices) == L:
            break

    assert len(selected_indices) == L, f"Could not find {L} samples without the '{target_class}' attribute."
    batch = torch.stack([dataset[i]["img"] for i in selected_indices]).to(device)

    # ---- OLD VERSION FOR REFERENCE ----
    # print("Loading data sample ...")
    # data = ImageDataset("imgs_align", image_size=autoenc_conf.img_size,
    #                     exts=["jpg", "JPG", "png"], do_augment=False)
    # L = 1
    # batch = data[0]["img"].unsqueeze(0).repeat(L, 1, 1, 1).to(device)
    # -----------------------------------

    # Encode
    cond = model.encode(batch)
    T_render = riem_config.get("T_render", 250)
    xT = model.encode_stochastic(batch, cond, T=T_render)
    latent_shape = cond.shape[1:]
    x0_flat = flatten_tensor(cond)

    # Normalize
    assert getattr(cls_model.conf, "manipulate_znormalize", False) and getattr(model.conf, "latent_znormalize", False)
    x0_flat_normalized = cls_model.normalize(x0_flat)
    riem_config["initial_point"] = x0_flat_normalized

    # Time setup
    t_val = compute_discrete_time_from_target_snr(riem_config, autoenc_conf)
    t_latent = torch.full((1,), t_val, dtype=torch.float32, device=device)

    # Diffusion & score functions
    print("Building latent diffusion process ...")
    latent_diffusion = autoenc_conf.make_latent_eval_diffusion_conf().make_sampler()
    latent_wrapper = DiffusionWrapper(latent_diffusion)
    try:
        snr_val = latent_wrapper.snr(t_latent)
        print(f"Latent diffusion SNR at t={t_val}: {snr_val.mean().item():.4f}")
    except Exception as e:
        print("Could not compute latent SNR:", e)

    score_fn = get_score_fn(latent_wrapper, model.ema_model.latent_net, t_latent, latent_shape)
    denoiser_fn = get_denoiser_fn(latent_wrapper, model.ema_model.latent_net, t_latent, latent_shape)
    retraction_fn = create_retraction_fn(
        retraction_type=riem_config.get("retraction_operator", "identity"),
        denoiser_fn=denoiser_fn
    )

    # Define optimization objective
    classifier_weight = riem_config.get("classifier_weight", 1.0)
    reg_norm_weight = riem_config.get("reg_norm_weight", 0.5)
    reg_norm_type = riem_config.get("reg_norm_type", "L2")
    classifier_fn = get_classifier_fn(cls_model, torch.zeros_like(t_latent), latent_shape)
    opt_fn = get_opt_fn(classifier_fn, cls_id, latent_shape, x0_flat_normalized,
                        classifier_weight, reg_norm_weight, reg_norm_type)

    # Run optimization
    print("Running Riemannian optimization ...")
    riem_opt = get_riemannian_optimizer(score_fn, opt_fn, riem_config, retraction_fn)
    start_time = time.time()
    trajectory, metrics = riem_opt.run()
    elapsed_time = time.time() - start_time
    print(f"Riemannian optimization completed in {elapsed_time:.2f} seconds.")

    # Visualization
    output_dir = riem_config.get('log_dir', 'logs')
    denorm_trajectory = [cls_model.denormalize(latent) for latent in trajectory]
    traj_save_path = os.path.join(output_dir, "trajectory.png")
    rendered_images = visualize_trajectory(model, xT, denorm_trajectory, latent_shape, T_render, traj_save_path, fast_mode=True)
    gif_path = os.path.join(output_dir, "trajectory.gif")
    save_gif_from_rendered_images(rendered_images, gif_path, duration_sec=6)


def main():
    mp.set_start_method("spawn", force=True)
    parser = ArgumentParser(description="Riemannian Optimization on Autoencoder Latent Space")
    parser.add_argument("--ro-config", type=str, required=True, help="Path to the riemannian config file")
    args = parser.parse_args()
    riemannian_optimization(args.ro_config)

if __name__ == "__main__":
    main()
